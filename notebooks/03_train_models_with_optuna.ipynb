{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UI82fFlYtp_D"
   },
   "source": [
    "# 03 - Train Models WITH Optuna\n",
    "\n",
    "This notebook trains **8 classification models** with Optuna hyperparameter tuning.\n",
    "\n",
    "## Models\n",
    "1. Logistic Regression\n",
    "2. Ridge Classifier\n",
    "3. HistGradientBoostingClassifier\n",
    "4. XGBoost\n",
    "\n",
    "## Conditions\n",
    "- 4 models WITHOUT PCA + Optuna tuning\n",
    "- 4 models WITH PCA + Optuna tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 567,
     "status": "ok",
     "timestamp": 1766160873889,
     "user": {
      "displayName": "Teja Anumolu",
      "userId": "10736921857654930462"
     },
     "user_tz": 300
    },
    "id": "8dju6N3Ptp_G",
    "outputId": "22eab60f-2553-43e2-c377-8244d33d24fe"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7001,
     "status": "ok",
     "timestamp": 1766160873313,
     "user": {
      "displayName": "Teja Anumolu",
      "userId": "10736921857654930462"
     },
     "user_tz": 300
    },
    "id": "2tmLj9IUtp_I",
    "outputId": "2f927639-1d1b-47f6-ab0f-ee961bb18e7d"
   },
   "outputs": [],
   "source": [
    "!pip install optuna xgboost lightgbm \"mlflow<3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1766160876794,
     "user": {
      "displayName": "Teja Anumolu",
      "userId": "10736921857654930462"
     },
     "user_tz": 300
    },
    "id": "xle8jm1Atp_J"
   },
   "outputs": [],
   "source": [
    "base_folder = \"/content/drive/MyDrive/Colab Notebooks/drug_review_classification\"\n",
    "db_path = f\"{base_folder}/data/drug_reviews.db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11023,
     "status": "ok",
     "timestamp": 1766160889282,
     "user": {
      "displayName": "Teja Anumolu",
      "userId": "10736921857654930462"
     },
     "user_tz": 300
    },
    "id": "-2YpuePttp_J"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import joblib\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "from sklearn.base import clone\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import mlflow\n",
    "\n",
    "start_time = time.monotonic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2447,
     "status": "ok",
     "timestamp": 1766160892789,
     "user": {
      "displayName": "Teja Anumolu",
      "userId": "10736921857654930462"
     },
     "user_tz": 300
    },
    "id": "L-XSuBp7tp_J",
    "outputId": "8a68b812-2349-4424-ddeb-09afea28b026"
   },
   "outputs": [],
   "source": [
    "# Load data from database\n",
    "def get_dataframe_from_db(db_path):\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    df = pd.read_sql(\"\"\"\n",
    "        SELECT\n",
    "            d.drug_name as urlDrugName,\n",
    "            c.condition_name as condition,\n",
    "            r.benefits_review as benefitsReview,\n",
    "            r.side_effects_review as sideEffectsReview,\n",
    "            r.comments_review as commentsReview,\n",
    "            r.rating,\n",
    "            s.side_effect_name as sideEffects,\n",
    "            e.effectiveness_name as effectiveness,\n",
    "            r.split\n",
    "        FROM reviews r\n",
    "        JOIN drugs d ON r.drug_id = d.drug_id\n",
    "        JOIN conditions c ON r.condition_id = c.condition_id\n",
    "        JOIN side_effects s ON r.side_effect_id = s.side_effect_id\n",
    "        JOIN effectiveness_levels e ON r.effectiveness_id = e.effectiveness_id\n",
    "    \"\"\", conn)\n",
    "    conn.close()\n",
    "    return df\n",
    "\n",
    "df = get_dataframe_from_db(db_path)\n",
    "\n",
    "# Build combined text\n",
    "df[\"combined_text\"] = (\n",
    "    df[\"benefitsReview\"].fillna(\"\") + \" \" +\n",
    "    df[\"sideEffectsReview\"].fillna(\"\") + \" \" +\n",
    "    df[\"commentsReview\"].fillna(\"\")\n",
    ").str.strip()\n",
    "\n",
    "# ✅ Remove empty texts (prevents TF-IDF having tiny feature count)\n",
    "df = df[df[\"combined_text\"].str.len() > 0].copy()\n",
    "\n",
    "# Split\n",
    "df_train = df[df[\"split\"] == \"train\"].copy()\n",
    "df_test  = df[df[\"split\"] == \"test\"].copy()\n",
    "\n",
    "# Encode target\n",
    "EFFECTIVENESS_ORDER = [\"Ineffective\", \"Marginally Effective\", \"Moderately Effective\",\n",
    "                       \"Considerably Effective\", \"Highly Effective\"]\n",
    "le = LabelEncoder()\n",
    "le.fit(EFFECTIVENESS_ORDER)\n",
    "y_train = le.transform(df_train[\"effectiveness\"])\n",
    "y_test  = le.transform(df_test[\"effectiveness\"])\n",
    "\n",
    "# ✅ TF-IDF (slightly safer settings)\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=2000,\n",
    "    ngram_range=(1, 2),\n",
    "    stop_words=\"english\",\n",
    "    min_df=2\n",
    ")\n",
    "X_train_tfidf = tfidf.fit_transform(df_train[\"combined_text\"])\n",
    "X_test_tfidf  = tfidf.transform(df_test[\"combined_text\"])\n",
    "\n",
    "# ✅ Safe SVD components\n",
    "n_features = X_train_tfidf.shape[1]\n",
    "n_comp = min(100, n_features - 1)   # must be <= n_features-1\n",
    "n_comp = max(2, n_comp)             # at least 2\n",
    "\n",
    "pca = TruncatedSVD(n_components=n_comp, random_state=42)\n",
    "X_train_pca = pca.fit_transform(X_train_tfidf)\n",
    "X_test_pca  = pca.transform(X_test_tfidf)\n",
    "\n",
    "print(f\"Train: {len(df_train)}, Test: {len(df_test)}\")\n",
    "print(f\"TF-IDF features: {n_features} | Using n_components: {n_comp}\")\n",
    "print(f\"TF-IDF shape: {X_train_tfidf.shape}, PCA shape: {X_train_pca.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1330,
     "status": "ok",
     "timestamp": 1766160897075,
     "user": {
      "displayName": "Teja Anumolu",
      "userId": "10736921857654930462"
     },
     "user_tz": 300
    },
    "id": "wdgxheaCtp_K",
    "outputId": "19daedba-9886-4d5d-d264-d9d49478ff01"
   },
   "outputs": [],
   "source": [
    "# Configure MLflow\n",
    "load_dotenv(dotenv_path=f\"{base_folder}/notebooks/.env\", override=True)\n",
    "\n",
    "MLFLOW_TRACKING_URI = os.getenv(\"MLFLOW_TRACKING_URI\")\n",
    "MLFLOW_TRACKING_USERNAME = os.getenv(\"MLFLOW_TRACKING_USERNAME\")\n",
    "MLFLOW_TRACKING_PASSWORD = os.getenv(\"MLFLOW_TRACKING_PASSWORD\")\n",
    "\n",
    "if MLFLOW_TRACKING_USERNAME:\n",
    "    os.environ[\"MLFLOW_TRACKING_USERNAME\"] = MLFLOW_TRACKING_USERNAME\n",
    "if MLFLOW_TRACKING_PASSWORD:\n",
    "    os.environ[\"MLFLOW_TRACKING_PASSWORD\"] = MLFLOW_TRACKING_PASSWORD\n",
    "\n",
    "if MLFLOW_TRACKING_URI:\n",
    "    mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "mlflow.set_experiment(\"drug_review_classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 68,
     "status": "ok",
     "timestamp": 1766160901951,
     "user": {
      "displayName": "Teja Anumolu",
      "userId": "10736921857654930462"
     },
     "user_tz": 300
    },
    "id": "RvJOBy1Utp_L"
   },
   "outputs": [],
   "source": [
    "# Optuna objective functions (NO PCA)\n",
    "def objective_logistic(trial, X, y):\n",
    "    C = trial.suggest_float('C', 0.01, 10.0, log=True)\n",
    "    solver = trial.suggest_categorical('solver', ['lbfgs', 'saga'])\n",
    "    clf = LogisticRegression(C=C, solver=solver, max_iter=1000, random_state=42, n_jobs=-1)\n",
    "    scores = cross_val_score(clf, X, y, cv=3, scoring='f1_macro', n_jobs=-1)\n",
    "    return scores.mean()\n",
    "\n",
    "def objective_ridge(trial, X, y):\n",
    "    alpha = trial.suggest_float('alpha', 0.01, 100.0, log=True)\n",
    "    clf = RidgeClassifier(alpha=alpha, random_state=42)\n",
    "    scores = cross_val_score(clf, X, y, cv=3, scoring='f1_macro', n_jobs=-1)\n",
    "    return scores.mean()\n",
    "\n",
    "def objective_hgb(trial, X, y):\n",
    "    lr = trial.suggest_float('learning_rate', 0.01, 0.3)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 10)\n",
    "    max_iter = trial.suggest_int('max_iter', 100, 300)\n",
    "    clf = HistGradientBoostingClassifier(learning_rate=lr, max_depth=max_depth, max_iter=max_iter, random_state=42)\n",
    "    scores = cross_val_score(clf, X, y, cv=3, scoring='f1_macro', n_jobs=-1)\n",
    "    return scores.mean()\n",
    "\n",
    "def objective_xgb(trial, X, y):\n",
    "    lr = trial.suggest_float('learning_rate', 0.01, 0.3)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 10)\n",
    "    n_estimators = trial.suggest_int('n_estimators', 100, 300)\n",
    "    clf = XGBClassifier(learning_rate=lr, max_depth=max_depth, n_estimators=n_estimators, objective='multi:softprob', eval_metric='mlogloss', random_state=42, n_jobs=-1, use_label_encoder=False)\n",
    "    scores = cross_val_score(clf, X, y, cv=3, scoring='f1_macro', n_jobs=-1)\n",
    "    return scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "d970ef537f324e4489254c8dc802cf5f",
      "2cdaa8ab70414f05a01f1e2becbdeec5",
      "84db6f2f00dc4022917e693b28fe4bd4",
      "6e771947ecbb4c09b3b17ae503dd3b9a",
      "56685d3139264103a0bafc48f70bd821",
      "e902c12c5f8647ee91cff8a7bc6f1871",
      "b7e007ff9e0a4f81ba5c4d2a9daf3976",
      "0d2ed98613594e1790020539a5210cc7",
      "ec976f2d923546449ad67184e9a95d9d",
      "326824262c6e457bad25a927ae69e2ae",
      "8876eb0d1abb4973a36b71523320f0c5",
      "b94d82e7d2a741fb93d9ab07857ecd84",
      "d38856e988fc4d9f9cc648582a04ac26",
      "0b357c940f74476a8371e47f4a6541d6",
      "844bfef574d046ccb9ae249f17b16a32",
      "d391e0c5f0fa4f328a8edc885c343033",
      "e709291714c745b5a8f53eba84f1cf76",
      "b02f06e322bf44a8a24dc0f4492d1ea1",
      "4fce7524251f4c03ab064c38cd6491b1",
      "ec999bdcd0424cd0aef5f15b0e300146",
      "c07c7044ad8642999dbf677b8699c92b",
      "10c9f02f3b154e58ae02b693886dfb00",
      "e2e067305b6a48cf860f607d007fb280",
      "2f6a9a625e2c4ae482cf0315bb35780f",
      "86a3e879416f4230826b4eb6bef83110",
      "5931a9fdfcc94073b97d4a88111407c3",
      "526194c5323140389e83292225639e3b",
      "f0a626e1569d4ae68d73fce2b80da8e0",
      "d4655b2e7a484ddd99b6705f8288e935",
      "461e3f7fcda5400c9516726015aa1a58",
      "4f6e5c8dda6448a8abc436c88f386565",
      "a6bf4d7cd56a4d8ea1fee0e85a46ff42",
      "378e039e6da442b08d61b824b01e0120",
      "ddb6358d1b9243f6a56d8a427d85d033",
      "7bbefe2639824563896b325a2aa1dd5e",
      "e1b267d22a7e48499991c431bcff541b",
      "97a3006324ff4e959de7f90bc88a3d38",
      "78370336bf1a42d39ab89b1325b41a2d",
      "8e92116315ca44dcbece161f5b0b87d9",
      "c6946d2126b94fe58199e61410c375d3",
      "b6fea07fa21349cdb0221356f94cd0e2",
      "3a6393fb51f44938ab86c97930b76985",
      "865be1f177014ab3afe715b5805868d3",
      "7473f6da504348d99935cbac87adf47d"
     ]
    },
    "executionInfo": {
     "elapsed": 106718,
     "status": "ok",
     "timestamp": 1766161012071,
     "user": {
      "displayName": "Teja Anumolu",
      "userId": "10736921857654930462"
     },
     "user_tz": 300
    },
    "id": "ztrSSdMFtp_L",
    "outputId": "b2858045-8018-4902-f0b3-25598a6d9a92"
   },
   "outputs": [],
   "source": [
    "# Train with Optuna (NO PCA)\n",
    "print(\"=\"*80)\n",
    "print(\"TRAINING WITH OPTUNA (NO PCA)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def objective_hgb(trial, X, y):\n",
    "    n_features = X.shape[1]\n",
    "    max_comp = max(2, min(300, n_features - 1))\n",
    "    n_components = trial.suggest_int(\"n_components\", 2, max_comp)\n",
    "\n",
    "    params = {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "        \"max_iter\": trial.suggest_int(\"max_iter\", 100, 400),\n",
    "        \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 10, 100),\n",
    "        \"l2_regularization\": trial.suggest_float(\"l2_regularization\", 0.0, 1.0),\n",
    "    }\n",
    "\n",
    "    clf = Pipeline([\n",
    "        (\"svd\", TruncatedSVD(n_components=n_components, random_state=42)),\n",
    "        (\"hgb\", HistGradientBoostingClassifier(random_state=42, **params))\n",
    "    ])\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    scores = cross_val_score(clf, X, y, cv=cv, scoring=\"f1_macro\", n_jobs=-1)\n",
    "    return float(np.mean(scores))\n",
    "\n",
    "\n",
    "objectives = {\n",
    "    'logistic': objective_logistic,\n",
    "    'ridge': objective_ridge,\n",
    "    'histgradientboosting': objective_hgb,\n",
    "    'xgboost': objective_xgb\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, obj_func in objectives.items():\n",
    "    print(f\"\\nOptimizing {name}...\")\n",
    "\n",
    "    study = optuna.create_study(direction='maximize', sampler=TPESampler(seed=42))\n",
    "    study.optimize(lambda trial: obj_func(trial, X_train_tfidf, y_train),\n",
    "                   n_trials=10, show_progress_bar=True, catch=(Exception,))\n",
    "\n",
    "    best_params = dict(study.best_params)   # copy so we can safely pop\n",
    "    cv_f1 = float(study.best_value)\n",
    "    print(f\"Best params: {best_params}\")\n",
    "    print(f\"Best CV F1: {cv_f1:.4f}\")\n",
    "\n",
    "    # Train final model (NO PCA)\n",
    "    if name == 'logistic':\n",
    "        clf = LogisticRegression(**best_params, max_iter=1000, random_state=42, n_jobs=-1)\n",
    "\n",
    "    elif name == 'ridge':\n",
    "        clf = RidgeClassifier(**best_params, random_state=42)\n",
    "\n",
    "    elif name == 'histgradientboosting':\n",
    "        # ✅ MUST be SVD + HGB even in \"NO PCA\" because TF-IDF is sparse\n",
    "        n_components = best_params.pop(\"n_components\")\n",
    "        clf = Pipeline([\n",
    "            (\"svd\", TruncatedSVD(n_components=n_components, random_state=42)),\n",
    "            (\"hgb\", HistGradientBoostingClassifier(random_state=42, **best_params))\n",
    "        ])\n",
    "\n",
    "    elif name == 'xgboost':\n",
    "        clf = XGBClassifier(\n",
    "            **best_params,\n",
    "            objective='multi:softprob',\n",
    "            eval_metric='mlogloss',\n",
    "            random_state=42,\n",
    "            n_jobs=-1,\n",
    "            use_label_encoder=False\n",
    "        )\n",
    "\n",
    "    clf.fit(X_train_tfidf, y_train)\n",
    "    y_pred = clf.predict(X_test_tfidf)\n",
    "    test_f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    print(f\"Test F1: {test_f1:.4f}\")\n",
    "\n",
    "    results[f\"{name}_optuna\"] = {\n",
    "        'cv_f1': cv_f1,\n",
    "        'test_f1': test_f1,\n",
    "        'uses_pca': False,\n",
    "        'is_tuned': True,\n",
    "        'model': clf,\n",
    "        'params': dict(study.best_params)\n",
    "    }\n",
    "\n",
    "    with mlflow.start_run(run_name=f\"{name}_optuna\"):\n",
    "        mlflow.log_param(\"model_family\", name)\n",
    "        mlflow.log_param(\"uses_pca\", False)\n",
    "        mlflow.log_param(\"is_tuned\", True)\n",
    "        mlflow.log_params(dict(study.best_params))\n",
    "        mlflow.log_metric(\"cv_f1\", cv_f1)\n",
    "        mlflow.log_metric(\"test_f1\", test_f1)\n",
    "\n",
    "        # ✅ remove MLflow signature warning by providing input_example\n",
    "        mlflow.sklearn.log_model(\n",
    "            clf,\n",
    "            artifact_path=\"model\",\n",
    "            registered_model_name=f\"{name}_pipeline_optuna\",\n",
    "            input_example=X_train_tfidf[:2].toarray()\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "35347bce88cb43859c6e836d2af6b7ca",
      "16f1384b42b24c388809f1c13a921c36",
      "32d6797255e646c8a277859509a87b92",
      "8adda4685ebd44fca6b6e106ec6d5dd8",
      "ae5d7bfa97e94ea2ab41daee0aedfdd6",
      "aa732db729fc4e86b310871ce5878381",
      "d47bf986ab0c4e288c569ffcb590be0b",
      "a9f6e2bc01dd4528808c99d6f705f7d1",
      "3c059458130442ec88129913e922136e",
      "10f1c66df26f42bb810773d552ce655c",
      "d4f90b526c344a11b04e9852614a3e57",
      "047a0ec977f1474aa8eeb3c905256010",
      "07e45180da44402886bc2a0b8179488d",
      "1cfc1b5c4b3a476ca9e0964741b5ec54",
      "1ab02b579f3a4200a012db92893a33e3",
      "dd0e16f976744c3495513870c89cb7e8",
      "7ecb64f6ce4e46a497f47f72e46e9370",
      "809adb725d2340dab427e780cee3abc0",
      "290a7374d8f24981b9663875259e94c7",
      "f2dfeca074704aa99ccc509713d6fa97",
      "5e81c426ede94ac6885d8db66246e918",
      "25635b1b3b4a4f7b9e21ea296e82fc5c",
      "abeeaae696be473fab42106e3d7523f4",
      "f11a7498e04f4b4ca77e87a6120e8129",
      "219af4d1396e4b5b907c63a34d4e8f38",
      "e8105f7d8cde47f7948e041dbcff15b8",
      "eff7d965be2049f7b642dcae4ef75c60",
      "37e5667174a34f79818d09b7d5d3a490",
      "44f114ae163243c4832cee7dfbd26e5e",
      "7683d9b12a644feb978ee409e0bedd45",
      "8e9d33f10c564ccda46b6dd7d87f1b1d",
      "7701d967eeae4c9599531008a214d0d4",
      "ff0e75d8fb704d719eb5c83b2059072e",
      "b2228fe61d2f4b49a5174857efbbcd62",
      "759b51e8a49042f79b4495b6d4acf7cf",
      "73cef21e0967439bb5349a4be8365768",
      "d898524072f142ffb7d3ba13bafde180",
      "5a9fb2a5344b479e8e4fbdf2ca413123",
      "89d024862b574dbfa84c5ff97285e041",
      "db28e79082f44a549481cab97c0a4211",
      "12bb274eced54dc7bdb1859b59ab5365",
      "632d9ceef85f4bb6ac3ec0f30a2faef7",
      "b46dee6a08144ae89218aa5cdca65765",
      "2e6386545e2a4801bd2fb6b225139df4"
     ]
    },
    "executionInfo": {
     "elapsed": 92721,
     "status": "ok",
     "timestamp": 1766161121907,
     "user": {
      "displayName": "Teja Anumolu",
      "userId": "10736921857654930462"
     },
     "user_tz": 300
    },
    "id": "SpadlBcXtp_M",
    "outputId": "486df35c-2ab5-48a6-b09c-71fae8277cdd"
   },
   "outputs": [],
   "source": [
    "# Train with Optuna (WITH PCA)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRAINING WITH OPTUNA (WITH PCA)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def objective_hgb_pca(trial, X, y):\n",
    "    params = {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "        \"max_iter\": trial.suggest_int(\"max_iter\", 100, 400),\n",
    "        \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 10, 100),\n",
    "        \"l2_regularization\": trial.suggest_float(\"l2_regularization\", 0.0, 1.0),\n",
    "    }\n",
    "    clf = HistGradientBoostingClassifier(random_state=42, **params)\n",
    "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    scores = cross_val_score(clf, X, y, cv=cv, scoring=\"f1_macro\", n_jobs=-1)\n",
    "    return float(np.mean(scores))\n",
    "\n",
    "# Build objectives dict for PCA run (use HGB_PCA objective here)\n",
    "objectives_pca = {\n",
    "    \"logistic\": objective_logistic,\n",
    "    \"ridge\": objective_ridge,\n",
    "    \"histgradientboosting\": objective_hgb_pca,\n",
    "    \"xgboost\": objective_xgb\n",
    "}\n",
    "\n",
    "for name, obj_func in objectives_pca.items():\n",
    "    print(f\"\\nOptimizing {name} with PCA...\")\n",
    "\n",
    "    study = optuna.create_study(direction=\"maximize\", sampler=TPESampler(seed=42))\n",
    "    study.optimize(lambda trial: obj_func(trial, X_train_pca, y_train),\n",
    "                   n_trials=10, show_progress_bar=True, catch=(Exception,))\n",
    "\n",
    "    best_params = dict(study.best_params)\n",
    "    cv_f1 = float(study.best_value)\n",
    "    print(f\"Best params: {best_params}\")\n",
    "    print(f\"Best CV F1: {cv_f1:.4f}\")\n",
    "\n",
    "    # Train final model (WITH PCA)\n",
    "    if name == \"logistic\":\n",
    "        clf = LogisticRegression(**best_params, max_iter=1000, random_state=42, n_jobs=-1)\n",
    "\n",
    "    elif name == \"ridge\":\n",
    "        clf = RidgeClassifier(**best_params, random_state=42)\n",
    "\n",
    "    elif name == \"histgradientboosting\":\n",
    "        clf = HistGradientBoostingClassifier(**best_params, random_state=42)\n",
    "\n",
    "    elif name == \"xgboost\":\n",
    "        clf = XGBClassifier(\n",
    "            **best_params,\n",
    "            objective=\"multi:softprob\",\n",
    "            eval_metric=\"mlogloss\",\n",
    "            random_state=42,\n",
    "            n_jobs=-1,\n",
    "            use_label_encoder=False\n",
    "        )\n",
    "\n",
    "    clf.fit(X_train_pca, y_train)\n",
    "    y_pred = clf.predict(X_test_pca)\n",
    "    test_f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "    print(f\"Test F1: {test_f1:.4f}\")\n",
    "\n",
    "    results[f\"{name}_pca_optuna\"] = {\n",
    "        \"cv_f1\": cv_f1,\n",
    "        \"test_f1\": test_f1,\n",
    "        \"uses_pca\": True,\n",
    "        \"is_tuned\": True,\n",
    "        \"model\": clf,\n",
    "        \"params\": dict(study.best_params)\n",
    "    }\n",
    "\n",
    "    with mlflow.start_run(run_name=f\"{name}_with_pca_optuna\"):\n",
    "        mlflow.log_param(\"model_family\", name)\n",
    "        mlflow.log_param(\"uses_pca\", True)\n",
    "        mlflow.log_param(\"is_tuned\", True)\n",
    "        mlflow.log_params(dict(study.best_params))\n",
    "        mlflow.log_metric(\"cv_f1\", cv_f1)\n",
    "        mlflow.log_metric(\"test_f1\", test_f1)\n",
    "        mlflow.sklearn.log_model(clf,artifact_path=\"model\",registered_model_name=f\"{name}_pipeline_with_pca_optuna\",input_example=X_train_pca[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 502,
     "status": "ok",
     "timestamp": 1766161249067,
     "user": {
      "displayName": "Teja Anumolu",
      "userId": "10736921857654930462"
     },
     "user_tz": 300
    },
    "id": "Zo0A_D3mtp_M",
    "outputId": "9d3869c0-015d-41c1-b426-8199c7810c98"
   },
   "outputs": [],
   "source": [
    "# Results summary\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RESULTS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for name, res in results.items():\n",
    "    print(f\"{name}: CV F1={res['cv_f1']:.4f}, Test F1={res['test_f1']:.4f}\")\n",
    "\n",
    "best_name = max(results, key=lambda x: results[x]['test_f1'])\n",
    "best_result = results[best_name]\n",
    "print(f\"\\nBest model: {best_name}\")\n",
    "print(f\"Best Test F1: {best_result['test_f1']:.4f}\")\n",
    "\n",
    "model_path = f\"{base_folder}/models/global_best_model_optuna.pkl\"\n",
    "joblib.dump(best_result['model'], model_path)\n",
    "print(f\"Best model saved to: {model_path}\")\n",
    "\n",
    "end_time = time.monotonic()\n",
    "elapsed = end_time - start_time\n",
    "print(f\"\\nTotal time: {int(elapsed//60)} minutes {elapsed%60:.2f} seconds\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
